{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgnUfKxWWjrt"
      },
      "source": [
        "# TRANSTAILOR METHOD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao5Fa39lWmsl"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d0AOWS5EWoYC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EuydGGwWq5p"
      },
      "source": [
        "## Load model and dataset\n",
        "* Model: VGG16\n",
        "* Dataset: CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bh_Mq4xW3Z9",
        "outputId": "9944f9f1-111c-41c1-d67a-136730da8bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE: \" + str(device))\n",
        "\n",
        "# Load the VGG16 model\n",
        "model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.IMAGENET1K_V1)\n",
        "batch_size = 128\n",
        "\n",
        "# Define the data transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the CIFAR10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "kwargs = {'num_workers': 10, 'pin_memory': True} if device == 'cuda' else {}\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "\n",
        "# Freeze the parameters of the model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the last layer of the model with a new layer that matches the number of classes in CIFAR10\n",
        "num_classes = 10\n",
        "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxtIR-tBLyK"
      },
      "source": [
        "## Finetune model based on target data CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the model from previous training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the model's parameters\n",
        "model.load_state_dict(torch.load('model_parameters_10_epochs.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we don't find any checkpoint, finetune for 10 epoches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAhreNjYXaHh",
        "outputId": "7f2ce609-36a0-43a6-c1a8-04a87bc8dd8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===Fine-tune the pre-trained model to generate W_s*===\n",
            "Epoch 0/10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10;\n",
        "\n",
        "# Fine-tune the pre-trained model to generate W_s*\n",
        "print(\"\\n===Fine-tune the pre-trained model to generate W_s*===\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch \" + str(epoch) + \"/\" + str(num_epochs))\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save model for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model's parameters\n",
        "torch.save(model.state_dict(), 'model_parameters_10_epochs.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYGF5cN4W7o_"
      },
      "source": [
        "## Define and traing scaling factor `Î±`\n",
        "\n",
        "1.   Train the scaling factors using the target data (CIFAR10 in this case).\n",
        "2.   Transform the scaling factors to the filter importance using the Taylor expansion method.\n",
        "3.   Prune the filters based on the filter importance.\n",
        "4.   Fine-tune the pruned model using the target data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-b0y-eNKdKHS"
      },
      "outputs": [],
      "source": [
        "def generate_scaling_factors(num_layers, num_filters):\n",
        "    scaling_factors = torch.zeros(num_layers, max(num_filters), requires_grad=True)\n",
        "    for i in range(num_layers):\n",
        "        with torch.no_grad():\n",
        "            scaling_factors[i, :num_filters[i]] = torch.rand(num_filters[i])\n",
        "    return scaling_factors\n",
        "\n",
        "num_layers = len(model.features)\n",
        "num_filters = [0] * num_layers\n",
        "\n",
        "for i in range(num_layers):\n",
        "    layer = model.features[i]\n",
        "    if isinstance(layer, torch.nn.Conv2d):\n",
        "        num_filters[i] = layer.out_channels\n",
        "\n",
        "alpha = generate_scaling_factors(num_layers, num_filters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "Rl0x_Gp8gauW",
        "outputId": "09f68cfa-57af-491c-8da8-31d5a92ffcfd"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "# filter_outputs = []\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the factors alpha by optimizing the loss function\n",
        "print(\"\\n===Train the factors alpha by optimizing the loss function===\")\n",
        "optimizer_alpha = torch.optim.SGD([alpha], lr=0.001, momentum=0.9)\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch \" + str(epoch) + \"/\" + str(num_epochs))\n",
        "    iter_count = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        if iter_count % 10 == 0:\n",
        "            print(\"Iteration \" + str(iter_count))\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        batch_size = inputs.shape[0]\n",
        "        optimizer_alpha.zero_grad()\n",
        "        outputs = inputs\n",
        "        # Freeze the output\n",
        "        outputs.requires_grad = False\n",
        "        for i in range(num_layers):\n",
        "            if isinstance(model.features[i], torch.nn.Conv2d):\n",
        "                outputs = model.features[i](outputs)\n",
        "                # Multiply the output of each filter by its corresponding scaling factor\n",
        "                alpha_i = alpha[i][:num_filters[i]]\n",
        "                for j in range(num_filters[i]):\n",
        "                    outputs[:, j, :, :] *= alpha_i[j]\n",
        "            else:\n",
        "                outputs = model.features[i](outputs)\n",
        "        outputs = torch.flatten(outputs, 1)\n",
        "        classification_output = model.classifier(outputs)\n",
        "        loss = criterion(classification_output, labels)\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "            loss.backward()\n",
        "        optimizer_alpha.step()\n",
        "        iter_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_alpha_to_beta(alpha, num_filters, num_layers):\n",
        "    beta = torch.zeros(sum(num_filters))\n",
        "    offset = 0\n",
        "    for i in range(num_layers):\n",
        "        if isinstance(model.features[i], torch.nn.Conv2d):\n",
        "            for j in range(num_filters[i]):\n",
        "                beta[offset + j] = torch.sum(torch.autograd.grad(\n",
        "                    outputs=criterion(classification_output, labels),\n",
        "                    inputs=alpha[i][j],\n",
        "                    grad_outputs=torch.ones_like(classification_output),\n",
        "                    retain_graph=True,\n",
        "                    create_graph=True\n",
        "                )[0])\n",
        "            offset += num_filters[i]\n",
        "    return beta\n",
        "\n",
        "beta = transform_alpha_to_beta(alpha, num_filters, num_layers)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
