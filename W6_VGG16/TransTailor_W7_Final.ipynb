{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wEJfN_vstI1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg16\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDJVNgr4swVG"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra và sử dụng GPU nếu có\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgcHtz5asysR",
        "outputId": "e968e687-1d6f-441a-f65a-327c7fc965a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "\n",
            "CIFAR-10 Dataset Information:\n",
            "Number of training samples: 1000\n",
            "Number of batches: 32\n",
            "Batch size: 32\n"
          ]
        }
      ],
      "source": [
        "def load_cifar10():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(254),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    subset_size = 1000\n",
        "    subset_indices = torch.randperm(len(trainset))[:subset_size]\n",
        "    subset = torch.utils.data.Subset(trainset, subset_indices)\n",
        "    trainset = subset\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "    return trainset, trainloader\n",
        "\n",
        "trainset, trainloader = load_cifar10()\n",
        "\n",
        "\n",
        "print(\"\\nCIFAR-10 Dataset Information:\")\n",
        "print(f\"Number of training samples: {len(trainset)}\")\n",
        "print(f\"Number of batches: {len(trainloader)}\")\n",
        "print(f\"Batch size: {trainloader.batch_size}\")\n",
        "\n",
        "# Result #\n",
        "Files already downloaded and verified\n",
        "\n",
        "CIFAR-10 Dataset Information:\n",
        "Number of training samples: 1000\n",
        "Number of batches: 32\n",
        "Batch size: 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0KGzSDCs1EG",
        "outputId": "7d890c79-9cda-450c-e85e-5df25ea8ba4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16 Model Structure:\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "def load_vgg16():\n",
        "    model = vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, 10)  # Thay đổi lớp cuối cùng cho CIFAR-10\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "model = load_vgg16()\n",
        "\n",
        "print(\"VGG16 Model Structure:\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQIYXuZKvYsY",
        "outputId": "5c5eb957-b7c5-452c-ca11-e1f8e1286d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số lượng tham số của mô hình ban đầu: 134301486\n"
          ]
        }
      ],
      "source": [
        "# Hàm để tính số lượng tham số của mô hình\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Số lượng tham số của mô hình ban đầu: {count_parameters(model)}\")\n",
        "\n",
        "#Result\n",
        "Số lượng tham số của mô hình ban đầu: 134301486"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llSDtpomacxg"
      },
      "outputs": [],
      "source": [
        "# 2. Thực hiện prune một filter và xem sự thay đổi về shape\n",
        "def prune_filter(model, layer_index, filter_index):\n",
        "    conv_layer = model.features[layer_index]\n",
        "    next_conv_layer = None\n",
        "    \n",
        "    # Tìm lớp tích chập tiếp theo\n",
        "    for layer in model.features[layer_index+1:]:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            next_conv_layer = layer\n",
        "            break\n",
        "\n",
        "    # Tạo một lớp tích chập mới với số filter giảm đi 1\n",
        "    new_conv = nn.Conv2d(in_channels=conv_layer.in_channels,\n",
        "                         out_channels=conv_layer.out_channels - 1,\n",
        "                         kernel_size=conv_layer.kernel_size,\n",
        "                         stride=conv_layer.stride,\n",
        "                         padding=conv_layer.padding,\n",
        "                         dilation=conv_layer.dilation,\n",
        "                         groups=conv_layer.groups,\n",
        "                         bias=conv_layer.bias is not None)\n",
        "\n",
        "    # Sao chép trọng số và bias, ngoại trừ filter được prune\n",
        "    new_filters = torch.cat((conv_layer.weight.data[:filter_index], conv_layer.weight.data[filter_index+1:]))\n",
        "    new_conv.weight.data = new_filters\n",
        "\n",
        "    if conv_layer.bias is not None:\n",
        "        new_biases = torch.cat((conv_layer.bias.data[:filter_index], conv_layer.bias.data[filter_index+1:]))\n",
        "        new_conv.bias.data = new_biases\n",
        "\n",
        "    # Thay thế lớp tích chập cũ bằng lớp mới trong mô hình\n",
        "    model.features[layer_index] = new_conv\n",
        "\n",
        "    # Điều chỉnh lớp tích chập tiếp theo nếu có\n",
        "    if next_conv_layer is not None:\n",
        "        next_new_conv = nn.Conv2d(in_channels=next_conv_layer.in_channels - 1,\n",
        "                                  out_channels=next_conv_layer.out_channels,\n",
        "                                  kernel_size=next_conv_layer.kernel_size,\n",
        "                                  stride=next_conv_layer.stride,\n",
        "                                  padding=next_conv_layer.padding,\n",
        "                                  dilation=next_conv_layer.dilation,\n",
        "                                  groups=next_conv_layer.groups,\n",
        "                                  bias=next_conv_layer.bias is not None)\n",
        "\n",
        "        next_new_conv.weight.data = next_conv_layer.weight.data[:, :filter_index, :, :].clone()\n",
        "        next_new_conv.weight.data = torch.cat([next_new_conv.weight.data, next_conv_layer.weight.data[:, filter_index+1:, :, :]], dim=1)\n",
        "\n",
        "        if next_conv_layer.bias is not None:\n",
        "            next_new_conv.bias.data = next_conv_layer.bias.data.clone()\n",
        "\n",
        "        # Tìm index của lớp tích chập tiếp theo\n",
        "        for i, layer in enumerate(model.features[layer_index+1:]):\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                next_layer_index = layer_index + 1 + i\n",
        "                break\n",
        "\n",
        "        model.features[next_layer_index] = next_new_conv\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poxIAHFfvRee",
        "outputId": "3720be91-9e43-4bba-fc25-6f5145c2a129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape của lớp tích chập đầu tiên trước khi pruning:\n",
            "torch.Size([64, 3, 3, 3])\n",
            "Shape của lớp tích chập đầu tiên sau khi pruning:\n",
            "torch.Size([63, 3, 3, 3])\n",
            "\n",
            "Số lượng tham số sau khi pruning: 138356940\n"
          ]
        }
      ],
      "source": [
        "# Prune filter đầu tiên của lớp tích chập đầu tiên\n",
        "pruned_model = prune_filter(copy.deepcopy(model), 0, 0)\n",
        "\n",
        "print(\"\\nShape của lớp tích chập đầu tiên trước khi pruning:\")\n",
        "print(model.features[0].weight.shape)\n",
        "print(\"Shape của lớp tích chập đầu tiên sau khi pruning:\")\n",
        "print(pruned_model.features[0].weight.shape)\n",
        "\n",
        "print(f\"\\nSố lượng tham số sau khi pruning: {count_parameters(pruned_model)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU2EvyOrtyQO"
      },
      "outputs": [],
      "source": [
        "# Hàm để tái cấu trúc mô hình\n",
        "def restructure_model(model, layer_index):\n",
        "    next_conv_layer = None\n",
        "    for i in range(layer_index + 1, len(model.features)):\n",
        "        if isinstance(model.features[i], nn.Conv2d):\n",
        "            next_conv_layer = model.features[i]\n",
        "            break\n",
        "\n",
        "    if next_conv_layer is not None:\n",
        "        new_in_channels = next_conv_layer.in_channels - 1\n",
        "        new_conv = nn.Conv2d(new_in_channels, next_conv_layer.out_channels,\n",
        "                             next_conv_layer.kernel_size, next_conv_layer.stride,\n",
        "                             next_conv_layer.padding, next_conv_layer.dilation,\n",
        "                             next_conv_layer.groups, bias=next_conv_layer.bias is not None)\n",
        "\n",
        "        # Sao chép trọng số, ngoại trừ kênh đầu vào bị loại bỏ\n",
        "        new_weights = next_conv_layer.weight.data[:, torch.arange(next_conv_layer.in_channels) != filter_index]\n",
        "        new_conv.weight.data = new_weights\n",
        "\n",
        "        if next_conv_layer.bias is not None:\n",
        "            new_conv.bias.data = next_conv_layer.bias.data\n",
        "\n",
        "        model.features[i] = new_conv\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hàm để tái cấu trúc mô hình\n",
        "def restructure_model(model, layer_index, filter_index):\n",
        "    for i in range(layer_index + 1, len(model.features)):\n",
        "        if isinstance(model.features[i], nn.Conv2d):\n",
        "            conv_layer = model.features[i]\n",
        "            new_in_channels = conv_layer.in_channels - 1\n",
        "            new_conv = nn.Conv2d(new_in_channels, conv_layer.out_channels,\n",
        "                                 conv_layer.kernel_size, conv_layer.stride,\n",
        "                                 conv_layer.padding, conv_layer.dilation,\n",
        "                                 conv_layer.groups, bias=conv_layer.bias is not None)\n",
        "            \n",
        "            # Sao chép trọng số, ngoại trừ kênh đầu vào bị loại bỏ\n",
        "            new_weights = conv_layer.weight.data[:, torch.arange(conv_layer.in_channels) != filter_index]\n",
        "            new_conv.weight.data = new_weights\n",
        "            \n",
        "            if conv_layer.bias is not None:\n",
        "                new_conv.bias.data = conv_layer.bias.data\n",
        "            \n",
        "            model.features[i] = new_conv\n",
        "        elif isinstance(model.features[i], nn.BatchNorm2d):\n",
        "            bn_layer = model.features[i]\n",
        "            new_bn = nn.BatchNorm2d(bn_layer.num_features - 1)\n",
        "            \n",
        "            # Sao chép các tham số, ngoại trừ feature bị loại bỏ\n",
        "            new_bn.weight.data = bn_layer.weight.data[torch.arange(bn_layer.num_features) != filter_index]\n",
        "            new_bn.bias.data = bn_layer.bias.data[torch.arange(bn_layer.num_features) != filter_index]\n",
        "            new_bn.running_mean = bn_layer.running_mean[torch.arange(bn_layer.num_features) != filter_index]\n",
        "            new_bn.running_var = bn_layer.running_var[torch.arange(bn_layer.num_features) != filter_index]\n",
        "            \n",
        "            model.features[i] = new_bn\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFWP_qUctz1R"
      },
      "outputs": [],
      "source": [
        "# Hàm để huấn luyện mô hình\n",
        "def train_model(model, trainloader, epochs=5):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    model.train\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "\n",
        "      # epoch_loss = running_loss / len(trainloader.dataset)\n",
        "      # print(f'Training Loss: {epoch_loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "      if i % 100 == 99:\n",
        "        print(f'[{epoch + 1}, {i + 1:5d}] | Training loss: {running_loss / 100:.3f}')\n",
        "        running_loss = 0.0\n",
        "    print('Finished Training')\n",
        "    return model, loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEzorHiFt15p"
      },
      "outputs": [],
      "source": [
        "# Hàm tổng quát để prune một filter bất kỳ và tái cấu trúc mô hình\n",
        "def prune_and_restructure(model, layer_index, filter_index):\n",
        "    model = prune_filter(model, layer_index, filter_index)\n",
        "    model = restructure_model(model, layer_index)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R7j4ghMz46w",
        "outputId": "fa4fa249-939d-4cf5-b08f-7f7cda9bee5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training mô hình gốc...\n",
            "Epoch 1/5\n",
            "----------\n",
            "Finished Training\n",
            "Thời gian training mô hình gốc: 2165.56 giây\n",
            "Loss cuối cùng của mô hình gốc: 4.8297\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining mô hình gốc...\")\n",
        "start_time = time.time()\n",
        "_, original_loss = train_model(model, trainloader)\n",
        "end_time = time.time()\n",
        "print(f\"Thời gian training mô hình gốc: {end_time - start_time:.2f} giây\")\n",
        "print(f\"Loss cuối cùng của mô hình gốc: {original_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaZJ3c-wz88P"
      },
      "outputs": [],
      "source": [
        "# Prune một filter và xem sự thay đổi\n",
        "layer_index = 0  # Ví dụ: prune filter đầu tiên của lớp conv đầu tiên\n",
        "filter_index = 0\n",
        "model = prune_filter(model, layer_index, filter_index)\n",
        "\n",
        "print(\"\\nModel structure after pruning:\")\n",
        "print(model)\n",
        "\n",
        "# Huấn luyện mô hình sau khi prune\n",
        "print(\"\\nTraining mô hình đã pruning...\")\n",
        "start_time = time.time()\n",
        "_, pruned_loss = train_model(pruned_model, trainloader, epochs = 1)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Thời gian training mô hình đã pruning: {end_time - start_time:.2f} giây\")\n",
        "print(f\"Loss cuối cùng của mô hình đã pruning: {pruned_loss:.4f}\")\n",
        "\n",
        "print(f\"\\nChênh lệch loss: {abs(original_loss - pruned_loss):.4f}\")\n",
        "\n",
        "# Tái cấu trúc mô hình\n",
        "model = restructure_model(model, layer_index)\n",
        "\n",
        "print(\"\\nModel structure after restructuring:\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs8ppx8M1BL_"
      },
      "outputs": [],
      "source": [
        "# Huấn luyện mô hình sau khi tái cấu trúc\n",
        "print(\"\\nTraining mô hình đã tái cấu trúc...\")\n",
        "start_time = time.time()\n",
        "_, restruct_loss = train_model(model, trainloader, epochs=1)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Thời gian training mô hình đã pruning: {end_time - start_time:.2f} giây\")\n",
        "print(f\"Loss cuối cùng của mô hình đã pruning: {restruct_loss:.4f}\")\n",
        "\n",
        "print(f\"\\nChênh lệch loss: {abs(original_loss - restruct_loss):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5V-wUn7sU5p"
      },
      "outputs": [],
      "source": [
        "# Sử dụng hàm tổng quát để prune và tái cấu trúc\n",
        "layer_index = 2  # Ví dụ: prune filter của lớp conv thứ 3\n",
        "filter_index = 1\n",
        "model = prune_and_restructure(model, layer_index, filter_index)\n",
        "\n",
        "print(\"\\nModel structure after pruning and restructuring using general function:\")\n",
        "print(model)\n",
        "\n",
        "# Huấn luyện mô hình cuối cùng\n",
        "print(\"\\nTraining mô hình...\")\n",
        "start_time = time.time()\n",
        "_, restruct_loss = train_model(model, trainloader, epochs=1)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Thời gian training mô hình đã pruning: {end_time - start_time:.2f} giây\")\n",
        "print(f\"Loss cuối cùng của mô hình đã pruning: {restruct_loss:.4f}\")\n",
        "\n",
        "print(f\"\\nChênh lệch loss: {abs(original_loss - restruct_loss):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
